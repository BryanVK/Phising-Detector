{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LMWEBMRSpk71","executionInfo":{"status":"error","timestamp":1671515914660,"user_tz":-420,"elapsed":6587,"user":{"displayName":"Bryan Viriya Kurniawan","userId":"12328472230767292525"}},"outputId":"e47f3172-e711-4629-d2c8-938a40eceebd","colab":{"base_uri":"https://localhost:8080/","height":571}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting whois\n","  Downloading whois-0.9.18.tar.gz (22 kB)\n","Building wheels for collected packages: whois\n","  Building wheel for whois (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for whois: filename=whois-0.9.18-py3-none-any.whl size=22447 sha256=d647951f719e760e723dd88226ccf2be2e524a75805a9184142196135fbb625a\n","  Stored in directory: /root/.cache/pip/wheels/69/72/a1/a9457b737e0812a77ce7085ccf230a13a8ef1bfb983355b13f\n","Successfully built whois\n","Installing collected packages: whois\n","Successfully installed whois-0.9.18\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-db7ace3b10cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mcomputer_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/AI project/raw_datasets/legitimate_urls.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"urls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mcomputer_raw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/AI project/raw_datasets/legitimate_urls.txt'"]}],"source":["# coding: utf-8\n","\n","# In[ ]:\n","\n","\n","# 0 - legitimate\n","# 1 - phishing\n","# 2 - suspicious\n","\n","\n","# In[84]:\n","\n","\n","# packages\n","!pip install whois\n","import pandas as pd\n","from urllib.parse import urlparse\n","import re\n","from bs4 import BeautifulSoup\n","import whois\n","import urllib.request\n","import time\n","import socket\n","from urllib.error import HTTPError\n","from datetime import  datetime\n","\n","\n","# In[67]:\n","\n","\n","# In[2]:\n","\n","\n","computer_raw_data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI project/raw_datasets/legitimate_urls.txt\",header=None,names=[\"urls\"])\n","computer_raw_data.head(10)\n","\n","\n","# In[36]:\n","\n","\n","computer_raw_data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI project/raw_datasets/1000-phishing.txt\",header=None,names=['urls'])\n","computer_raw_data\n","\n","\n","# In[3]:\n","\n","\n","rows = len(computer_raw_data)\n","\n","\n","# In[4]:\n","\n","\n","computer_raw_data[\"urls\"][0]\n","\n","\n","# In[85]:\n","\n","\n","cd = None\n","class FeatureExtraction:\n","    def __init__(self):\n","        pass\n","    \n","    def getProtocol(self,url):\n","        return urlparse(url).scheme\n","    \n","    def getDomain(self,url):\n","        return urlparse(url).netloc\n","    \n","    def getPath(self,url):\n","        return urlparse(url).path\n","    \n","    def havingIP(self,url):\n","        \"\"\"If the domain part has IP then it is phishing otherwise legitimate\"\"\"\n","        match=re.search('(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  #IPv4\n","                    '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)'  #IPv4 in hexadecimal\n","                    '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}',url)     #Ipv6\n","        if match:\n","            #print match.group()\n","            return 1            # phishing\n","        else:\n","            #print 'No matching pattern found'\n","            return 0            # legitimate\n","    \n","    def long_url(self,url):\n","        \"\"\"This function is defined in order to differntiate website based on the length of the URL\"\"\"\n","        if len(url) < 54:\n","            return 0            # legitimate\n","        elif len(url) >= 54 and len(url) <= 75:\n","            return 2            # suspicious\n","        else:\n","            return 1            # phishing\n","    \n","    def have_at_symbol(self,url):\n","        \"\"\"This function is used to check whether the URL contains @ symbol or not\"\"\"\n","        if \"@\" in url:\n","            return 1            # phishing\n","        else:\n","            return 0            # legitimate\n","    \n","    def redirection(self,url):\n","        \"\"\"If the url has symbol(//) after protocol then such URL is to be classified as phishing \"\"\"\n","        if \"//\" in urlparse(url).path:\n","            return 1            # phishing\n","        else:\n","            return 0            # legitimate\n","        \n","    def prefix_suffix_separation(self,url):\n","        \"\"\"If the domain has '-' symbol then it is considered as phishing site\"\"\"\n","        if \"-\" in urlparse(url).netloc:\n","            return 1            # phishing\n","        else:\n","            return 0            # legitimate\n","        \n","    def sub_domains(self,url):\n","        \"\"\"If the url has more than 3 dots then it is a phishing\"\"\"\n","        if url.count(\".\") < 3:\n","            return 0            # legitimate\n","        elif url.count(\".\") == 3:\n","            return 2            # suspicious\n","        else:\n","            return 1            # phishing\n","        \n","    def shortening_service(self,url):\n","        \"\"\"Tiny URL -> phishing otherwise legitimate\"\"\"\n","        match=re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n","                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n","                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n","                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n","                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n","                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n","                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net',url)\n","        if match:\n","            return 1               # phishing\n","        else:\n","            return 0               # legitimate\n","        \n","    \"\"\"\n","    def google_index(self,url):\n","        user_agent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36'\n","        headers = { 'User-Agent' : user_agent}\n","        query = {'q': 'info:' + url}\n","        google = \"https://www.google.com/search?\" + urlencode(query)\n","        #data = requests.get(google, headers=headers,proxies=proxies)\n","        data = requests.get(google,headers=headers)\n","        data.encoding = 'ISO-8859-1'\n","        soup = BeautifulSoup(str(data.content), \"html.parser\")\n","        try:\n","            check = soup.find(id=\"rso\").find(\"div\").find(\"div\").find(\"h3\").find(\"a\")\n","            if soup.find(id=\"rso\").find(\"div\").find(\"div\").find(\"h3\").find(\"a\").find(\"href\" != None):\n","                href = check['href']\n","                return 0 # indexed\n","            else:\n","                return 1\n","        except AttributeError:\n","            return 1 # indexed\n","        #print(\"Waiting \" + str(seconds) + \" seconds until checking next URL.\\n\")\n","        #time.sleep(float(seconds))\n","    \"\"\"\n","    \"\"\"\n","    def abnormal_url(self,url):\n","        dns = 0\n","        #domain_name = \"\"\n","        try:\n","            #domain = urlparse(url).netloc\n","            #print(domain)\n","            domain_name = whois.whois(urlparse(url).netloc)\n","            #print(domain_name)\n","        except:\n","            dns = 1\n","        \n","        if dns == 1:\n","            return 1 # phishing\n","        else:\n","            hostname=domain_name.domain_name\n","            #match=re.search(hostname,url)\n","            if hostname in url:\n","                return 0 # legitimate\n","            else:\n","                return 1 # phishing\n","    \"\"\"\n","    \n","    def web_traffic(self,url):\n","        try:\n","            rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\"REACH\")['RANK']\n","        except TypeError:\n","            return 1\n","        except HTTPError:\n","            return 2\n","        rank= int(rank)\n","        if (rank<100000):\n","            return 0\n","        else:\n","            return 2\n","        \n","    def domain_registration_length(self,url):\n","        dns = 0\n","        try:\n","            domain_name = whois.whois(urlparse(url).netloc)\n","        except:\n","            dns = 1\n","        \n","        if dns == 1:\n","            return 1      #phishing\n","        else:\n","            expiration_date = domain_name.expiration_date\n","            today = time.strftime('%Y-%m-%d')\n","            today = datetime.strptime(today, '%Y-%m-%d')\n","            if expiration_date is None:\n","                return 1\n","            elif type(expiration_date) is list or type(today) is list :\n","                return 2     #If it is a type of list then we can't select a single value from list. So,it is regarded as suspected website  \n","            else:\n","                creation_date = domain_name.creation_date\n","                expiration_date = domain_name.expiration_date\n","                if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n","                    try:\n","                        creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n","                        expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n","                    except:\n","                        return 2\n","                registration_length = abs((expiration_date - today).days)\n","                if registration_length / 365 <= 1:\n","                    return 1 #phishing\n","                else:\n","                    return 0 # legitimate\n","            \n","    def age_domain(self,url):\n","        dns = 0\n","        try:\n","            domain_name = whois.whois(urlparse(url).netloc)\n","        except:\n","            dns = 1\n","        \n","        if dns == 1:\n","            return 1\n","        else:\n","            creation_date = domain_name.creation_date\n","            expiration_date = domain_name.expiration_date\n","            if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n","                try:\n","                    creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n","                    expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n","                except:\n","                    return 2\n","            if ((expiration_date is None) or (creation_date is None)):\n","                return 1\n","            elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n","                return 2\n","            else:\n","                ageofdomain = abs((expiration_date - creation_date).days)\n","                if ((ageofdomain/30) < 6):\n","                    return 1\n","                else:\n","                    return 0\n","     \n","    \n","    def dns_record(self,url):\n","        dns = 0\n","        try:\n","            domain_name = whois.whois(urlparse(url).netloc)\n","            #rint(domain_name)\n","        except:\n","            dns = 1\n","        \n","        if dns == 1:\n","            return 1\n","        else:\n","            return 0\n","        \n","   \n","    def statistical_report(self,url):\n","        hostname = url\n","        h = [(x.start(0), x.end(0)) for x in re.finditer('https://|http://|www.|https://www.|http://www.', hostname)]\n","        z = int(len(h))\n","        if z != 0:\n","            y = h[0][1]\n","            hostname = hostname[y:]\n","            h = [(x.start(0), x.end(0)) for x in re.finditer('/', hostname)]\n","            z = int(len(h))\n","            if z != 0:\n","                hostname = hostname[:h[0][0]]\n","        url_match=re.search('at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly',url)\n","        try:\n","            ip_address = socket.gethostbyname(hostname)\n","            ip_match=re.search('146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42',ip_address)  \n","        except:\n","            return 1\n","\n","        if url_match:\n","            return 1\n","        else:\n","            return 0\n","        \n","    def https_token(self,url):\n","        match=re.search('https://|http://',url)\n","        try:\n","            if match.start(0)==0 and match.start(0) is not None:\n","                url=url[match.end(0):]\n","                match=re.search('http|https',url)\n","                if match:\n","                    return 1\n","                else:\n","                    return 0\n","        except:\n","            return 1\n","\n","\n","\n","\n","# In[86]:\n","\n","\n","#features\n","\n","google_index = []\n","\n","\n","# ### 0 - legitimate\n","# ### 1 - phishing\n","# ### 2 - suspicious\n","\n","# In[87]:\n","\n","\n","# object creation\n","def getAttributess(url):\n","    \n","    fe = FeatureExtraction()\n","    protocol = fe.getProtocol(url)\n","    path = fe.getPath(url)\n","    domain = fe.getDomain(url)\n","    having_ip = fe.havingIP(url)\n","    len_url = fe.long_url(url)\n","    having_at_symbol = fe.have_at_symbol(url)\n","    redirection_symbol = fe.redirection(url)\n","    prefix_suffix_separation = fe.prefix_suffix_separation(url)\n","    sub_domains = fe.sub_domains(url)\n","    tiny_url = fe.shortening_service(url)\n","    web_traffic = fe.web_traffic(url)\n","    domain_registration_length = fe.domain_registration_length(url)\n","    dns_record = fe.dns_record(url)\n","    statistical_report = fe.statistical_report(url)\n","    age_domain = fe.age_domain(url)\n","    http_tokens = fe.https_token(url)\n","    \n","    d={'Protocol':pd.Series(protocol),'Domain':pd.Series(domain),'Path':pd.Series(path),'Having_IP':pd.Series(having_ip),\n","   'URL_Length':pd.Series(len_url),'Having_@_symbol':pd.Series(having_at_symbol),\n","   'Redirection_//_symbol':pd.Series(redirection_symbol),'Prefix_suffix_separation':pd.Series(prefix_suffix_separation),\n","   'Sub_domains':pd.Series(sub_domains),'tiny_url':pd.Series(tiny_url),'web_traffic' : pd.Series(web_traffic) ,\n","   'domain_registration_length':pd.Series(domain_registration_length),'dns_record':pd.Series(dns_record),\n","   'statistical_report':pd.Series(statistical_report),'age_domain':pd.Series(age_domain),'http_tokens':pd.Series(http_tokens)}\n","    data=pd.DataFrame(d)\n","    data = data.drop(data.columns[[0,3,5]],axis=1)\n","    return data\n","    google_index.append(fe.google_index(url))\n","    abnormal_url.append(fe.abnormal_url(url))\n","    \n","#print(domain)\n","#print(protocol)\n","#print(ip)\n","#print(len_url)\n","#print(google_index)\n","#print(abnormal_url)\n","#print(web_traffic)\n","#print(domain_registration_length)\n","#print(age_domain)\n","#print(dns_record)\n","#print(statistical_report)\n","\n","\n","# In[88]:\n","\n","\n","label = []\n","for i in range(0,rows):\n","    label.append(1)\n","\n","\n","# In[89]:\n","\n","\n","\n","\n","\n","# In[11]:\n","\n","\n","#data.to_csv(\"legitimate-urls.csv\",index=False,encoding='UTF-8')\n","\n","\n","# In[90]:\n","\n","\n","#data.to_csv(\"phishing-urls.csv\",index=False,encoding='UTF-8')\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"B7a47oz1PPnN","executionInfo":{"status":"aborted","timestamp":1671515914662,"user_tz":-420,"elapsed":15,"user":{"displayName":"Bryan Viriya Kurniawan","userId":"12328472230767292525"}}},"execution_count":null,"outputs":[]}]}